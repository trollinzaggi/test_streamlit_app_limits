{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit Load Test Analysis\n",
    "This notebook analyzes the performance metrics collected from your Streamlit application to determine if it can handle 150-200 concurrent users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths\n",
    "# CHANGE THIS TO YOUR METRICS DIRECTORY\n",
    "METRICS_DIR = \"/path/to/your/metrics/directory\"\n",
    "REPORTS_DIR = \"/path/to/your/reports/directory\"\n",
    "\n",
    "# Date for the CSV files (today's date)\n",
    "csv_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# File paths\n",
    "operations_file = os.path.join(METRICS_DIR, f\"operation_metrics_{csv_date}.csv\")\n",
    "checkpoints_file = os.path.join(METRICS_DIR, f\"checkpoint_metrics_{csv_date}.csv\")\n",
    "summary_file = os.path.join(METRICS_DIR, f\"summary_metrics_{csv_date}.csv\")\n",
    "\n",
    "print(f\"Metrics directory: {METRICS_DIR}\")\n",
    "print(f\"Looking for files from date: {csv_date}\")\n",
    "print(f\"\\nChecking for files:\")\n",
    "for file in [operations_file, checkpoints_file, summary_file]:\n",
    "    exists = os.path.exists(file)\n",
    "    print(f\"  {os.path.basename(file)}: {'Found' if exists else 'Not found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "df_operations = None\n",
    "df_checkpoints = None\n",
    "df_summary = None\n",
    "\n",
    "if os.path.exists(operations_file):\n",
    "    df_operations = pd.read_csv(operations_file)\n",
    "    df_operations['timestamp'] = pd.to_datetime(df_operations['timestamp'])\n",
    "    print(f\"Operations data loaded: {len(df_operations)} records\")\n",
    "else:\n",
    "    print(\"Warning: Operations file not found\")\n",
    "\n",
    "if os.path.exists(checkpoints_file):\n",
    "    df_checkpoints = pd.read_csv(checkpoints_file)\n",
    "    df_checkpoints['timestamp'] = pd.to_datetime(df_checkpoints['timestamp'])\n",
    "    print(f\"Checkpoints data loaded: {len(df_checkpoints)} records\")\n",
    "else:\n",
    "    print(\"Warning: Checkpoints file not found\")\n",
    "\n",
    "if os.path.exists(summary_file):\n",
    "    df_summary = pd.read_csv(summary_file)\n",
    "    df_summary['timestamp'] = pd.to_datetime(df_summary['timestamp'])\n",
    "    print(f\"Summary data loaded: {len(df_summary)} records\")\n",
    "else:\n",
    "    print(\"Warning: Summary file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Load Test Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the report generator\n",
    "from memory_compute_tracker import generate_load_test_report\n",
    "\n",
    "# Generate comprehensive report\n",
    "report_path = generate_load_test_report(\n",
    "    metrics_dir=METRICS_DIR,\n",
    "    output_dir=REPORTS_DIR\n",
    ")\n",
    "\n",
    "print(f\"Report generated: {report_path}\")\n",
    "\n",
    "# Display report content\n",
    "with open(report_path, 'r') as f:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f.read())\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Operation Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_operations is not None and not df_operations.empty:\n",
    "    # Summary statistics by operation\n",
    "    operation_summary = df_operations.groupby('operation').agg({\n",
    "        'duration_seconds': ['count', 'mean', 'std', 'min', 'max'],\n",
    "        'peak_mb': ['mean', 'max'],\n",
    "        'final_increase_mb': ['mean', 'max'],\n",
    "        'avg_cpu_percent': ['mean', 'max'],\n",
    "        'had_spike': 'sum'\n",
    "    }).round(2)\n",
    "    \n",
    "    operation_summary.columns = ['_'.join(col).strip() for col in operation_summary.columns]\n",
    "    operation_summary = operation_summary.rename(columns={'duration_seconds_count': 'call_count'})\n",
    "    \n",
    "    print(\"OPERATION PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    display(operation_summary)\n",
    "    \n",
    "    # Identify problematic operations\n",
    "    print(\"\\nPROBLEMATIC OPERATIONS:\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    # Slow operations (>5 seconds average)\n",
    "    slow_ops = operation_summary[operation_summary['duration_seconds_mean'] > 5]\n",
    "    if not slow_ops.empty:\n",
    "        print(\"\\nSlow operations (>5s average):\")\n",
    "        for op in slow_ops.index:\n",
    "            print(f\"  - {op}: {slow_ops.loc[op, 'duration_seconds_mean']:.2f}s average\")\n",
    "    \n",
    "    # Memory intensive operations (>100MB peak average)\n",
    "    memory_ops = operation_summary[operation_summary['peak_mb_mean'] > 100]\n",
    "    if not memory_ops.empty:\n",
    "        print(\"\\nMemory intensive operations (>100MB average peak):\")\n",
    "        for op in memory_ops.index:\n",
    "            print(f\"  - {op}: {memory_ops.loc[op, 'peak_mb_mean']:.0f}MB average peak\")\n",
    "    \n",
    "    # Operations with memory spikes\n",
    "    spike_ops = operation_summary[operation_summary['had_spike_sum'] > 0]\n",
    "    if not spike_ops.empty:\n",
    "        print(\"\\nOperations with memory spikes:\")\n",
    "        for op in spike_ops.index:\n",
    "            print(f\"  - {op}: {spike_ops.loc[op, 'had_spike_sum']:.0f} spikes\")\n",
    "else:\n",
    "    print(\"No operations data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Memory Usage Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_summary is not None and not df_summary.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Memory over time\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(df_summary['timestamp'], df_summary['current_memory_mb'], label='Current', linewidth=2)\n",
    "    ax1.plot(df_summary['timestamp'], df_summary['peak_memory_mb'], label='Peak', linewidth=2, alpha=0.7)\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Memory (MB)')\n",
    "    ax1.set_title('Memory Usage Over Time')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Active sessions over time\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(df_summary['timestamp'], df_summary['active_sessions'], color='green', linewidth=2)\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Active Sessions')\n",
    "    ax2.set_title('Concurrent Sessions Over Time')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: CPU usage over time\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(df_summary['timestamp'], df_summary['cpu_percent'], color='red', linewidth=2)\n",
    "    ax3.axhline(y=80, color='orange', linestyle='--', label='Warning threshold')\n",
    "    ax3.set_xlabel('Time')\n",
    "    ax3.set_ylabel('CPU %')\n",
    "    ax3.set_title('CPU Usage Over Time')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: 150-user projection over time\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.plot(df_summary['timestamp'], df_summary['projection_150_users_gb'], color='purple', linewidth=2)\n",
    "    ax4.axhline(y=200, color='red', linestyle='--', label='Fail threshold (200GB)')\n",
    "    ax4.axhline(y=150, color='orange', linestyle='--', label='Warning threshold (150GB)')\n",
    "    ax4.set_xlabel('Time')\n",
    "    ax4.set_ylabel('Projected Memory (GB)')\n",
    "    ax4.set_title('150-User Memory Projection')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nMEMORY STATISTICS:\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Current memory range: {df_summary['current_memory_mb'].min():.0f} - {df_summary['current_memory_mb'].max():.0f} MB\")\n",
    "    print(f\"Peak memory reached: {df_summary['peak_memory_mb'].max():.0f} MB\")\n",
    "    print(f\"Average memory: {df_summary['current_memory_mb'].mean():.0f} MB\")\n",
    "    print(f\"\\nMax concurrent sessions: {df_summary['active_sessions'].max()}\")\n",
    "    print(f\"Average CPU usage: {df_summary['cpu_percent'].mean():.1f}%\")\n",
    "    print(f\"Peak CPU usage: {df_summary['cpu_percent'].max():.1f}%\")\n",
    "else:\n",
    "    print(\"No summary data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Operation Performance Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_operations is not None and not df_operations.empty:\n",
    "    # Get unique operations\n",
    "    operations = df_operations['operation'].unique()\n",
    "    \n",
    "    if len(operations) > 0:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Duration distribution\n",
    "        ax1 = axes[0, 0]\n",
    "        for op in operations:\n",
    "            op_data = df_operations[df_operations['operation'] == op]['duration_seconds']\n",
    "            ax1.hist(op_data, alpha=0.5, label=op, bins=20)\n",
    "        ax1.set_xlabel('Duration (seconds)')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('Operation Duration Distribution')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Memory increase distribution\n",
    "        ax2 = axes[0, 1]\n",
    "        for op in operations:\n",
    "            op_data = df_operations[df_operations['operation'] == op]['final_increase_mb']\n",
    "            ax2.hist(op_data, alpha=0.5, label=op, bins=20)\n",
    "        ax2.set_xlabel('Memory Increase (MB)')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_title('Memory Increase Distribution')\n",
    "        ax2.legend()\n",
    "        \n",
    "        # Peak memory by operation\n",
    "        ax3 = axes[1, 0]\n",
    "        peak_by_op = df_operations.groupby('operation')['peak_mb'].agg(['mean', 'max'])\n",
    "        x_pos = np.arange(len(peak_by_op.index))\n",
    "        ax3.bar(x_pos - 0.2, peak_by_op['mean'], 0.4, label='Average Peak', alpha=0.8)\n",
    "        ax3.bar(x_pos + 0.2, peak_by_op['max'], 0.4, label='Maximum Peak', alpha=0.8)\n",
    "        ax3.set_xlabel('Operation')\n",
    "        ax3.set_ylabel('Memory (MB)')\n",
    "        ax3.set_title('Peak Memory by Operation')\n",
    "        ax3.set_xticks(x_pos)\n",
    "        ax3.set_xticklabels(peak_by_op.index, rotation=45, ha='right')\n",
    "        ax3.legend()\n",
    "        \n",
    "        # CPU usage by operation\n",
    "        ax4 = axes[1, 1]\n",
    "        cpu_by_op = df_operations.groupby('operation')['avg_cpu_percent'].agg(['mean', 'max'])\n",
    "        x_pos = np.arange(len(cpu_by_op.index))\n",
    "        ax4.bar(x_pos - 0.2, cpu_by_op['mean'], 0.4, label='Average CPU', alpha=0.8)\n",
    "        ax4.bar(x_pos + 0.2, cpu_by_op['max'], 0.4, label='Maximum CPU', alpha=0.8)\n",
    "        ax4.set_xlabel('Operation')\n",
    "        ax4.set_ylabel('CPU %')\n",
    "        ax4.set_title('CPU Usage by Operation')\n",
    "        ax4.set_xticks(x_pos)\n",
    "        ax4.set_xticklabels(cpu_by_op.index, rotation=45, ha='right')\n",
    "        ax4.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No operations data available for distribution analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Capacity Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_summary is not None and not df_summary.empty:\n",
    "    print(\"LOAD CAPACITY ASSESSMENT FOR 150 USERS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get latest metrics\n",
    "    latest = df_summary.iloc[-1]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_projection = df_summary['projection_150_users_gb'].mean()\n",
    "    max_projection = df_summary['projection_150_users_gb'].max()\n",
    "    min_projection = df_summary['projection_150_users_gb'].min()\n",
    "    std_projection = df_summary['projection_150_users_gb'].std()\n",
    "    \n",
    "    print(f\"\\nProjection Statistics:\")\n",
    "    print(f\"  Latest projection: {latest['projection_150_users_gb']:.2f} GB\")\n",
    "    print(f\"  Average projection: {avg_projection:.2f} GB\")\n",
    "    print(f\"  Minimum projection: {min_projection:.2f} GB\")\n",
    "    print(f\"  Maximum projection: {max_projection:.2f} GB\")\n",
    "    print(f\"  Standard deviation: {std_projection:.2f} GB\")\n",
    "    \n",
    "    print(f\"\\nPer-User Estimates:\")\n",
    "    print(f\"  Current estimate: {latest['estimated_per_user_mb']:.1f} MB per user\")\n",
    "    print(f\"  Max observed: {df_summary['estimated_per_user_mb'].max():.1f} MB per user\")\n",
    "    \n",
    "    print(f\"\\nTest Conditions:\")\n",
    "    print(f\"  Max concurrent sessions tested: {df_summary['active_sessions'].max()}\")\n",
    "    print(f\"  Total operations: {latest['total_operations']}\")\n",
    "    \n",
    "    # Make assessment\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL ASSESSMENT:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Use worst-case (maximum) projection for conservative assessment\n",
    "    if max_projection > 200:\n",
    "        print(\"❌ FAIL - Application will NOT handle 150 users\")\n",
    "        print(f\"\\nReason: Worst-case memory projection ({max_projection:.1f} GB) exceeds 200 GB limit\")\n",
    "        print(\"\\nRequired Actions:\")\n",
    "        print(\"  1. Implement @st.cache_resource on JSON loading (critical)\")\n",
    "        print(\"  2. Reduce session state memory usage\")\n",
    "        print(\"  3. Optimize memory-intensive operations\")\n",
    "        \n",
    "    elif max_projection > 150:\n",
    "        print(\"⚠️  WARNING - Application may struggle with 150 users\")\n",
    "        print(f\"\\nReason: Worst-case memory projection ({max_projection:.1f} GB) is in warning zone\")\n",
    "        print(\"\\nRecommended Actions:\")\n",
    "        print(\"  1. Monitor closely during deployment\")\n",
    "        print(\"  2. Consider implementing caching optimizations\")\n",
    "        print(\"  3. Have scaling plan ready\")\n",
    "        \n",
    "    else:\n",
    "        print(\"✅ PASS - Application should handle 150 users\")\n",
    "        print(f\"\\nWorst-case projection: {max_projection:.1f} GB (well within limits)\")\n",
    "        print(\"\\nRecommendations:\")\n",
    "        print(\"  1. Proceed with deployment\")\n",
    "        print(\"  2. Monitor initial production usage\")\n",
    "        print(\"  3. Set up alerts for memory > 100GB\")\n",
    "    \n",
    "    # Additional warnings\n",
    "    if df_summary['cpu_percent'].max() > 80:\n",
    "        print(\"\\n⚠️  Additional Warning: High CPU usage detected\")\n",
    "        print(f\"  Peak CPU: {df_summary['cpu_percent'].max():.1f}%\")\n",
    "        print(\"  CPU may become a bottleneck before memory\")\n",
    "        \n",
    "else:\n",
    "    print(\"No summary data available for assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dataframe for export\n",
    "if df_summary is not None and not df_summary.empty:\n",
    "    export_data = {\n",
    "        'Metric': [\n",
    "            'Latest Memory Projection (GB)',\n",
    "            'Average Memory Projection (GB)',\n",
    "            'Maximum Memory Projection (GB)',\n",
    "            'Estimated Per User (MB)',\n",
    "            'Peak Memory Observed (MB)',\n",
    "            'Max Concurrent Sessions',\n",
    "            'Total Operations',\n",
    "            'Average CPU %',\n",
    "            'Peak CPU %',\n",
    "            'Assessment'\n",
    "        ],\n",
    "        'Value': [\n",
    "            f\"{df_summary['projection_150_users_gb'].iloc[-1]:.2f}\",\n",
    "            f\"{df_summary['projection_150_users_gb'].mean():.2f}\",\n",
    "            f\"{df_summary['projection_150_users_gb'].max():.2f}\",\n",
    "            f\"{df_summary['estimated_per_user_mb'].iloc[-1]:.1f}\",\n",
    "            f\"{df_summary['peak_memory_mb'].max():.0f}\",\n",
    "            f\"{df_summary['active_sessions'].max()}\",\n",
    "            f\"{df_summary['total_operations'].max()}\",\n",
    "            f\"{df_summary['cpu_percent'].mean():.1f}\",\n",
    "            f\"{df_summary['cpu_percent'].max():.1f}\",\n",
    "            \"PASS\" if df_summary['projection_150_users_gb'].max() < 150 else \n",
    "            \"WARNING\" if df_summary['projection_150_users_gb'].max() < 200 else \"FAIL\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(export_data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    export_file = os.path.join(REPORTS_DIR, f\"load_test_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\")\n",
    "    summary_df.to_csv(export_file, index=False)\n",
    "    \n",
    "    print(\"Summary Results:\")\n",
    "    print(\"=\"*40)\n",
    "    display(summary_df)\n",
    "    print(f\"\\nResults exported to: {export_file}\")\n",
    "else:\n",
    "    print(\"No data available for export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OPTIMIZATION RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if df_operations is not None and not df_operations.empty:\n",
    "    # Find the most resource-intensive operations\n",
    "    top_memory_ops = df_operations.groupby('operation')['peak_mb'].max().nlargest(3)\n",
    "    top_time_ops = df_operations.groupby('operation')['duration_seconds'].mean().nlargest(3)\n",
    "    \n",
    "    print(\"\\n1. OPTIMIZE THESE OPERATIONS FIRST:\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    print(\"\\nHighest Memory Usage:\")\n",
    "    for op, mem in top_memory_ops.items():\n",
    "        print(f\"  - {op}: {mem:.0f} MB peak\")\n",
    "        if 'json' in op.lower():\n",
    "            print(\"    → Add @st.cache_resource decorator\")\n",
    "        elif 'pdf' in op.lower():\n",
    "            print(\"    → Process in chunks, clear buffers after use\")\n",
    "        elif 'llm' in op.lower() or 'openai' in op.lower():\n",
    "            print(\"    → Reduce context size, implement streaming\")\n",
    "    \n",
    "    print(\"\\nSlowest Operations:\")\n",
    "    for op, time in top_time_ops.items():\n",
    "        print(f\"  - {op}: {time:.2f} seconds average\")\n",
    "        if time > 5:\n",
    "            print(\"    → Add retry logic and timeout handling\")\n",
    "\n",
    "if df_summary is not None and not df_summary.empty:\n",
    "    max_projection = df_summary['projection_150_users_gb'].max()\n",
    "    \n",
    "    print(\"\\n2. CRITICAL FIXES BASED ON PROJECTION:\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    if max_projection > 150:\n",
    "        print(\"\\nIMPLEMENT IMMEDIATELY:\")\n",
    "        print(\"  1. JSON Caching with @st.cache_resource (saves ~99% memory)\")\n",
    "        print(\"  2. Add retry logic to Azure OpenAI calls\")\n",
    "        print(\"  3. Implement concurrency limits (semaphores)\")\n",
    "        print(\"  4. Clear unnecessary session state data\")\n",
    "    else:\n",
    "        print(\"\\nOPTIONAL OPTIMIZATIONS:\")\n",
    "        print(\"  1. Implement request queuing for better load distribution\")\n",
    "        print(\"  2. Add monitoring alerts for memory > 100GB\")\n",
    "        print(\"  3. Consider horizontal scaling if load exceeds 200 users\")\n",
    "\n",
    "print(\"\\n3. TESTING RECOMMENDATIONS:\")\n",
    "print(\"-\"*40)\n",
    "print(\"  - Test with at least 20-30 concurrent users\")\n",
    "print(\"  - Monitor for at least 30 minutes\")\n",
    "print(\"  - Test all major operations multiple times\")\n",
    "print(\"  - Verify caching is working (second loads should be instant)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Analysis complete. Review the report and implement recommended fixes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}